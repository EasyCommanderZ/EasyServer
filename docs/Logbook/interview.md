# 面试可能的问题

## 项目的优点？难点？

1. 通过 Epoll + 多Reactor 多线程的工作模式，可以达到比较高的连接并发量；

2. 整个处理模型都是以事件驱动的，通过设置事件类channel的事件处理函数来实现不同的功能。如果有新的业务需求，可以通过实现不同的事件处理函数来完成；

3. 对于类的设计基本遵守RAII规则，比如：

   1. 需要引用其他类对象的引用的时候都使用智能指针；

   2. 在日志库的类的析构函数中注意了对缓冲节点的解引用，使得能够通过智能指针自动释放缓冲节点；

   3. 在log的析构中也注意了对于单例模式申请的指针的释放；

   4. 在有创建子工作线程需要返回的时候都会用锁存器或者condition_variable来确保线程已经运行起来了，防止对于工作线程的空访问 

      所以目前使用 Valgrind 测试之后没有内存泄漏的情况出现；

4. 代码的结构比较分离，耦合性比较低。比如：

   1. Reactor 模型中的事件类 Channel 是通过绑定回调函数来进行对应的时间处理的，所以如果有新类型的事件，只需要编写新的事件处理函数就可以复用这个并发模型；
   2. 日志库的实现很完整，从文件写入类，到缓冲区节点、到日志前端所采用的日志类（同步、异步、或者其他的定制需求）都是可插拔的，可以很方便的对日志进行定制和优化，稍微修改一下日志的格式就可以直接拿出来放到另外一个项目用；

5. 测试和设计都有比较详细的记录吧，至少目前的功能来说暂时还没有什么bug，性能和同类型的项目比也还可以

难点的话：

1. 首先就是这个并发模型的设计吧，虽然前面说到了耦合度低，但是在实现的时候有些概念还是很容易搞混，例如这个并发模型的工作流的具体任务流向，事件的回调函数到底是在哪里触发的。这个我也是在参考了很多其他人的设计之后边实现才边搞明白的
2. 这个日志库其实也比较复杂，是项目里代码数量做多的部分之一，而且和服务器其实没什么关系。主要是这种日志库的层次结构的设计比较复杂，也是学习了一下一个性能比较高且扩展性比较强的日志库大概需要怎么设计实现；
3. 实现中其实也有很多问题，比如我是边写这个项目边学习的C++多线程编程，对多线程的数据共享和同步不是很熟悉，犯了很多错误，也是在项目中慢慢的通过犯错debug的。锁的错误使用导致死锁就不谈了，在写Http事件类的时候还出现了两个shared_ptr互指导致资源无法释放的典型错误（http 和 channel 关联）
4. RAII这里其实也花了比较大的功夫，主要还是容易忽视的资源释放比较多，比如日志实例的指针的释放，日志的缓冲节点的释放，以及在事件移出的时候事件类channel，事件处理类http和计时器都需要解引用
5. 刚开始http请求的处理使用的是正则表达式，后来发现代码虽然短，但是太慢了，只能通过更复杂的状态机来解析。

## 还能改进的地方？

首先是日志模块，从底向上

1. 目前只实现了一个定长的缓冲区，缓冲区的大小目前手动设置为 4MB。如果单条日志的内容大小超过 4MB，程序可能会出错。因为日志写的逻辑是前端往后端写，后端往文件写，虽然是双缓冲区，但是前后端的缓冲区使用的是同一类型的定长缓冲。

   解决思路：

   - 超过界限可以自动扩容一次的变长缓冲
   - 对日志进行切割，但是不知道怎么解决一次性写不完的问题
   - 单独为大文件日志设置一个申请大号缓冲区的逻辑，目前看来这个比较合理

2. Http的请求处理中，输入输出的缓冲区使用的是 std::string，虽然代码上的编写比较方便，但是效率没有 char* 高

然后对于server：

1. 目前还是只能解析http请求，并且只能解析get和head，关于POST等请求的解析设计还没想明白，如果直接写在代码里太臃肿了，应该对于不同的请求设计不同的解析函数才对。现在请求解析都是写在一起的。
2. 因为epoll，目前只能在linux上使用，没有完成跨平台。
3. 目前的并发性能应该黑可以继续提高，但是我目前还没有找到问题在哪
4. 配置文件需要手动修改，设计成nginx那种读配置文件的会更好